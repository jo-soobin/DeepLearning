{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 출처: https://github.com/deepseasw/seq2seq_chatbot<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq에서의 임베딩이 이전 예제와 다른 점은 아래와 같이 태그를 사용한다는 것입니다.<br>\n",
    "임베딩의 0~3번째에 각각 PADDING, START, END, OOV 태그를 넣습니다.<br>\n",
    "사실 그냥 똑같은 단어라고 보시면 됩니다. 다만 이 단어들이 Seq2Seq의 동작을 제어합니다. <br>\n",
    "<br>\n",
    "예를 들어, 디코더 입력에 START가 들어가면 디코딩의 시작을 의미합니다. 반대로 디코더 출력에 END가 나오면 디코딩을 종료합니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그 단어\n",
    "PAD = \"<PADDING>\"   # 패딩\n",
    "STA = \"<START>\"     # 시작\n",
    "END = \"<END>\"       # 끝\n",
    "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)\n",
    "\n",
    "# 태그 인덱스\n",
    "PAD_INDEX = 0\n",
    "STA_INDEX = 1\n",
    "END_INDEX = 2\n",
    "OOV_INDEX = 3\n",
    "\n",
    "# 데이터 타입\n",
    "ENCODER_INPUT  = 0\n",
    "DECODER_INPUT  = 1\n",
    "DECODER_TARGET = 2\n",
    "\n",
    "# 한 문장에서 단어 시퀀스의 최대 개수\n",
    "max_sequences = 30\n",
    "\n",
    "# 임베딩 벡터 차원\n",
    "embedding_dim = 100\n",
    "\n",
    "# LSTM 히든레이어 차원\n",
    "lstm_hidden_dim = 128\n",
    "\n",
    "# 정규 표현식 필터\n",
    "RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")\n",
    "\n",
    "# 챗봇 데이터 로드\n",
    "chatbot_data = pd.read_csv('./ChatbotData.csv', encoding='utf-8')\n",
    "question, answer = list(chatbot_data['Q']), list(chatbot_data['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "챗봇의 훈련을 위해서 송영숙님이 공개한 한글 데이터셋을 로드합니다.<br>\n",
    "질문과 대답, 감정 등 총 3개의 항목으로 구성되어 있습니다.<br>\n",
    "감정 분류는 Seq2Seq에 필요가 없기 때문에 사용하지 않습니다.<br>\n",
    "https://github.com/songys/Chatbot_data<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11824"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 개수\n",
    "len(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 12시 땡!\n",
      "A : 하루가 또 가네요.\n",
      "\n",
      "Q : 1지망 학교 떨어졌어\n",
      "A : 위로해 드립니다.\n",
      "\n",
      "Q : 3박4일 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : 3박4일 정도 놀러가고 싶다\n",
      "A : 여행은 언제나 좋죠.\n",
      "\n",
      "Q : PPL 심하네\n",
      "A : 눈살이 찌푸려지죠.\n",
      "\n",
      "Q : SD카드 망가졌어\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SD카드 안돼\n",
      "A : 다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Q : SNS 맞팔 왜 안하지ㅠㅠ\n",
      "A : 잘 모르고 있을 수도 있어요.\n",
      "\n",
      "Q : SNS 시간낭비인 거 아는데 매일 하는 중\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n",
      "Q : SNS 시간낭비인데 자꾸 보게됨\n",
      "A : 시간을 정하고 해보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 일부만 학습에 사용\n",
    "question = question[:100]\n",
    "answer = answer[:100]\n",
    "\n",
    "# 챗봇 데이터 출력\n",
    "for i in range(10):\n",
    "    print('Q : ' + question[i])\n",
    "    print('A : ' + answer[i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 단어 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소분석 함수\n",
    "def pos_tag(sentences):\n",
    "    \n",
    "    # KoNLPy 형태소분석기 설정\n",
    "    tagger = Okt()\n",
    "    \n",
    "    # 문장 품사 변수 초기화\n",
    "    sentences_pos = []\n",
    "    \n",
    "    # 모든 문장 반복\n",
    "    for sentence in sentences:\n",
    "        # 특수기호 제거\n",
    "        # RE_FILTER에 해당되는 정규표현식 char에 대하여 \"\" ()로 바꾸어라\n",
    "        sentence = re.sub(RE_FILTER, \"\", sentence)\n",
    "        \n",
    "        # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
    "        sentence = \" \".join(tagger.morphs(sentence))\n",
    "        sentences_pos.append(sentence)\n",
    "        \n",
    "    return sentences_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 12시 땡\n",
      "A : 하루 가 또 가네요\n",
      "\n",
      "Q : 1 지망 학교 떨어졌어\n",
      "A : 위로 해 드립니다\n",
      "\n",
      "Q : 3 박 4일 놀러 가고 싶다\n",
      "A : 여행 은 언제나 좋죠\n",
      "\n",
      "Q : 3 박 4일 정도 놀러 가고 싶다\n",
      "A : 여행 은 언제나 좋죠\n",
      "\n",
      "Q : PPL 심하네\n",
      "A : 눈살 이 찌푸려지죠\n",
      "\n",
      "Q : SD 카드 망가졌어\n",
      "A : 다시 새로 사는 게 마음 편해요\n",
      "\n",
      "Q : SD 카드 안 돼\n",
      "A : 다시 새로 사는 게 마음 편해요\n",
      "\n",
      "Q : SNS 맞팔 왜 안 하지 ㅠㅠ\n",
      "A : 잘 모르고 있을 수도 있어요\n",
      "\n",
      "Q : SNS 시간 낭비 인 거 아는데 매일 하는 중\n",
      "A : 시간 을 정 하고 해보세요\n",
      "\n",
      "Q : SNS 시간 낭비 인데 자꾸 보게 됨\n",
      "A : 시간 을 정 하고 해보세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 형태소분석 수행\n",
    "question = pos_tag(question)\n",
    "answer = pos_tag(answer)\n",
    "\n",
    "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
    "for i in range(10):\n",
    "    print('Q : ' + question[i])\n",
    "    print('A : ' + answer[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 대답 문장들을 하나로 합침\n",
    "sentences = []\n",
    "sentences.extend(question)\n",
    "sentences.extend(answer)\n",
    "\n",
    "words = []\n",
    "\n",
    "# 단어들의 배열 생성\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        words.append(word)\n",
    "\n",
    "# 길이가 0인 단어는 삭제\n",
    "words = [word for word in words if len(word) > 0]\n",
    "\n",
    "# 중복된 단어 삭제\n",
    "words = list(set(words))\n",
    "\n",
    "# 제일 앞에 태그 단어 삽입\n",
    "words[:0] = [PAD, STA, END, OOV]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문과 대답 문장들을 합쳐서 전체 단어 사전을 만듭니다.<br>\n",
    "자연어처리에서는 항상 이렇게 단어를 인덱스에 따라 정리를 해야 합니다.<br>\n",
    "<br>\n",
    "그래야지 문장을 인덱스 배열로 바꿔서 임베딩 레이어에 넣을 수 있습니다.<br>\n",
    "또한 모델의 출력에서 나온 인덱스를 다시 단어로 변환하는데도 필요합니다.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 개수\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PADDING>',\n",
       " '<START>',\n",
       " '<END>',\n",
       " '<OOV>',\n",
       " '맞팔',\n",
       " '을',\n",
       " '는',\n",
       " '보게',\n",
       " '되나',\n",
       " '싶은데',\n",
       " '하세요',\n",
       " '에',\n",
       " '나오세요',\n",
       " '왔나',\n",
       " '그런거니',\n",
       " '처럼',\n",
       " '들',\n",
       " '필요하죠',\n",
       " '갑작스러웠나',\n",
       " '박',\n",
       " '돌아가서',\n",
       " '선생님',\n",
       " '물어',\n",
       " '책임질',\n",
       " '벗어나는',\n",
       " 'PPL',\n",
       " '죠',\n",
       " '난다',\n",
       " '제일',\n",
       " '사랑',\n",
       " '강원도',\n",
       " '가까워질',\n",
       " '다시',\n",
       " '옷',\n",
       " '보고',\n",
       " '정',\n",
       " '씨방',\n",
       " '알',\n",
       " '나',\n",
       " '많이',\n",
       " '맛있게',\n",
       " '사세요',\n",
       " '언제나',\n",
       " '있는',\n",
       " '어디',\n",
       " '부모님',\n",
       " '빼고',\n",
       " '먹었는데',\n",
       " '이야기',\n",
       " '시간',\n",
       " '으로',\n",
       " '휴식',\n",
       " '짧죠',\n",
       " '될',\n",
       " '알려',\n",
       " '있을',\n",
       " '학교',\n",
       " '무시',\n",
       " '도',\n",
       " '보내고',\n",
       " '먹을까',\n",
       " '믿어',\n",
       " '개시',\n",
       " '켜고',\n",
       " '거',\n",
       " '이랑',\n",
       " '득템',\n",
       " '바라요',\n",
       " '했길',\n",
       " '그',\n",
       " '습관',\n",
       " '싶다',\n",
       " '시켜',\n",
       " '기회',\n",
       " '준',\n",
       " '돼겠지',\n",
       " '붙잡고',\n",
       " '개인',\n",
       " '의',\n",
       " '좋아요',\n",
       " '설움',\n",
       " '카드',\n",
       " '못',\n",
       " '입어볼까',\n",
       " '개강',\n",
       " '해보여',\n",
       " '막',\n",
       " '간접흡연',\n",
       " '해볼까',\n",
       " '이나',\n",
       " 'ㅠㅠ',\n",
       " '망가졌어',\n",
       " '와',\n",
       " '좋겠네요',\n",
       " '3',\n",
       " '있을까',\n",
       " '살찐',\n",
       " '쇼핑',\n",
       " '쫄딱',\n",
       " '떨어졌어',\n",
       " '가야',\n",
       " '없죠',\n",
       " '간다',\n",
       " '개념',\n",
       " '가보세요',\n",
       " '좋아해주세요',\n",
       " '어서',\n",
       " '것',\n",
       " '켜놓고',\n",
       " '데',\n",
       " '새',\n",
       " '서먹해졌어',\n",
       " '간장',\n",
       " '때',\n",
       " '먹고',\n",
       " '여행',\n",
       " '했잖아',\n",
       " '지망',\n",
       " '있어요',\n",
       " '있으면',\n",
       " '하고',\n",
       " '생활',\n",
       " '하자고',\n",
       " '사는',\n",
       " '가서',\n",
       " '수도',\n",
       " '드는',\n",
       " '키워',\n",
       " '끼리',\n",
       " '비싼데',\n",
       " '걸린',\n",
       " '땀',\n",
       " '좋겠다',\n",
       " '버렸어',\n",
       " '자꾸',\n",
       " '싫다',\n",
       " '가출',\n",
       " '나왔다',\n",
       " '같이',\n",
       " '땡',\n",
       " '힘든데',\n",
       " '집',\n",
       " '감정',\n",
       " '더',\n",
       " '어제',\n",
       " '중',\n",
       " '오늘이',\n",
       " '단',\n",
       " '같아',\n",
       " '병원',\n",
       " '좋아',\n",
       " '진창',\n",
       " '있어도',\n",
       " '이라니',\n",
       " '수',\n",
       " '하는지',\n",
       " '반',\n",
       " '저',\n",
       " '같',\n",
       " '않을',\n",
       " '비',\n",
       " '볼까',\n",
       " '꼈어',\n",
       " '에요',\n",
       " '해보세요',\n",
       " '눈물',\n",
       " '졸려',\n",
       " '닮아서',\n",
       " '까',\n",
       " '갈까',\n",
       " '보고싶었나',\n",
       " '고고',\n",
       " '간식',\n",
       " '감',\n",
       " '싫어',\n",
       " '피',\n",
       " '업무',\n",
       " '걔',\n",
       " '가지',\n",
       " '부족했나',\n",
       " '알아차리지',\n",
       " '떨리니까',\n",
       " '생각',\n",
       " '즐기세요',\n",
       " '알아차려도',\n",
       " '심하네',\n",
       " '가고',\n",
       " '지',\n",
       " '모르고',\n",
       " '주는',\n",
       " '됨',\n",
       " '매일',\n",
       " '걸리겠어',\n",
       " '들어올',\n",
       " '정도',\n",
       " '있어',\n",
       " '정말',\n",
       " '싶어',\n",
       " '인거',\n",
       " '쓰레기통',\n",
       " '됐으면',\n",
       " '감미로운',\n",
       " '나온거',\n",
       " '편해요',\n",
       " '감히',\n",
       " '진리',\n",
       " '은',\n",
       " '부터는',\n",
       " '돈',\n",
       " '취미',\n",
       " '싫어하지',\n",
       " '에는',\n",
       " '없어',\n",
       " '풀었어',\n",
       " '말까',\n",
       " '이에요',\n",
       " '온',\n",
       " '가려고',\n",
       " '자도',\n",
       " '애',\n",
       " '해봐요',\n",
       " '확실한',\n",
       " '건데',\n",
       " '적',\n",
       " '봐서',\n",
       " '절약',\n",
       " '감기',\n",
       " '자신',\n",
       " '즐거운',\n",
       " '가장',\n",
       " '게임',\n",
       " '수영장',\n",
       " '하루',\n",
       " '보면',\n",
       " '나를',\n",
       " '싫어요',\n",
       " '나갔어',\n",
       " '다음',\n",
       " '애가',\n",
       " '갈거야',\n",
       " '가스',\n",
       " '를',\n",
       " '어떤것',\n",
       " '가기',\n",
       " '좋다',\n",
       " '해도',\n",
       " '기름',\n",
       " '내일',\n",
       " '낭비하지',\n",
       " '결정',\n",
       " '중요해요',\n",
       " '상황',\n",
       " '해주세요',\n",
       " '가족',\n",
       " '왜',\n",
       " '하는데',\n",
       " '위로',\n",
       " '같은',\n",
       " '집어서',\n",
       " '무모한',\n",
       " '하',\n",
       " '할',\n",
       " '4일',\n",
       " '요',\n",
       " '인게',\n",
       " '친구',\n",
       " '떨리는',\n",
       " '빨리',\n",
       " '망함',\n",
       " '게',\n",
       " '만들어',\n",
       " '누구',\n",
       " '눈살',\n",
       " '방학',\n",
       " '식혀주세요',\n",
       " '기관',\n",
       " '처음',\n",
       " '함께',\n",
       " '좋은',\n",
       " '먼저',\n",
       " '만나지',\n",
       " '먹어야지',\n",
       " '참',\n",
       " '아는데',\n",
       " '가세',\n",
       " '이다',\n",
       " '관리',\n",
       " '두',\n",
       " '자의',\n",
       " '기운',\n",
       " '놀러',\n",
       " '서먹해',\n",
       " '12시',\n",
       " '자리',\n",
       " '불편한',\n",
       " '말랭이',\n",
       " '가난한',\n",
       " '이',\n",
       " '야',\n",
       " '해',\n",
       " '사람',\n",
       " '간만',\n",
       " '데이터',\n",
       " '안',\n",
       " '잊고',\n",
       " '중요한',\n",
       " '물어보세요',\n",
       " '달',\n",
       " '너무',\n",
       " '아세요',\n",
       " '인데',\n",
       " '자체',\n",
       " '드립니다',\n",
       " '건',\n",
       " '3초',\n",
       " '가자고',\n",
       " '최고',\n",
       " '공적',\n",
       " '쉬는',\n",
       " '갑자기',\n",
       " '패턴',\n",
       " '가네요',\n",
       " '드세요',\n",
       " '아름다운',\n",
       " '끄고',\n",
       " '입어',\n",
       " '놓고',\n",
       " '로',\n",
       " '그건',\n",
       " '살까',\n",
       " '개',\n",
       " '곧',\n",
       " '봅니다',\n",
       " '세수',\n",
       " '아픈가요',\n",
       " '찌푸려지죠',\n",
       " '가',\n",
       " '랑',\n",
       " '행복',\n",
       " '만',\n",
       " '당신',\n",
       " '연락',\n",
       " '들더라',\n",
       " '서로',\n",
       " '스트레스',\n",
       " '줘',\n",
       " '봐요',\n",
       " '그게',\n",
       " '엉망',\n",
       " '되도록',\n",
       " '오세요',\n",
       " '까지',\n",
       " '누굴',\n",
       " '하면',\n",
       " '강렬한',\n",
       " '남겨야',\n",
       " '같아요',\n",
       " '부터',\n",
       " '치킨',\n",
       " '했어',\n",
       " '그럴',\n",
       " '역시',\n",
       " '뭘',\n",
       " '리지',\n",
       " '컨트롤',\n",
       " '하겠어',\n",
       " '일도',\n",
       " '아님',\n",
       " '새로',\n",
       " '궁금해',\n",
       " '인',\n",
       " '살펴',\n",
       " '사이',\n",
       " '불',\n",
       " '괜찮아요',\n",
       " '일',\n",
       " '운',\n",
       " '된',\n",
       " '낮잠',\n",
       " '할까',\n",
       " '연인',\n",
       " '룩',\n",
       " '곳',\n",
       " '끌',\n",
       " '오려나',\n",
       " '키울까',\n",
       " '사는게',\n",
       " '장난',\n",
       " '갈',\n",
       " '예쁘게',\n",
       " '옴',\n",
       " '낭비',\n",
       " '돼',\n",
       " '관계',\n",
       " '콕',\n",
       " '가끔',\n",
       " '강아지',\n",
       " '가상',\n",
       " '바빠서',\n",
       " '되겠네요',\n",
       " '변화',\n",
       " '출발',\n",
       " '자랑',\n",
       " '가만',\n",
       " '추천',\n",
       " '첫인상',\n",
       " '하느라',\n",
       " '이럴',\n",
       " '짠으로',\n",
       " '좋더라',\n",
       " '되',\n",
       " '나쁜',\n",
       " '후회',\n",
       " '하지',\n",
       " '물어봐서',\n",
       " '따뜻하게',\n",
       " '어필',\n",
       " '키우고',\n",
       " '이야',\n",
       " '목소리',\n",
       " '싶네요',\n",
       " '모두',\n",
       " '듣고',\n",
       " '강의',\n",
       " '한테',\n",
       " '좋죠',\n",
       " '하는',\n",
       " '말',\n",
       " '마음',\n",
       " '뭐',\n",
       " '당황',\n",
       " '개학',\n",
       " '예요',\n",
       " '잠깐',\n",
       " 'SNS',\n",
       " '잘',\n",
       " '시켜야지',\n",
       " '또',\n",
       " '고민',\n",
       " '약',\n",
       " 'SD',\n",
       " '내',\n",
       " '화폐',\n",
       " '매력',\n",
       " '1',\n",
       " '다',\n",
       " '혼자',\n",
       " '니까',\n",
       " '키울',\n",
       " '질질',\n",
       " '보세요',\n",
       " '소중해요',\n",
       " '마세요',\n",
       " '살쪄도']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 출력\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어와 인덱스의 딕셔너리 생성, Series.count_values()도 가능\n",
    "word_to_index = {word: index for index, word in enumerate(words)}\n",
    "index_to_word = {index: word for index, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PADDING>': 0,\n",
       " '<START>': 1,\n",
       " '<END>': 2,\n",
       " '<OOV>': 3,\n",
       " '맞팔': 4,\n",
       " '을': 5,\n",
       " '는': 6,\n",
       " '보게': 7,\n",
       " '되나': 8,\n",
       " '싶은데': 9,\n",
       " '하세요': 10,\n",
       " '에': 11,\n",
       " '나오세요': 12,\n",
       " '왔나': 13,\n",
       " '그런거니': 14,\n",
       " '처럼': 15,\n",
       " '들': 16,\n",
       " '필요하죠': 17,\n",
       " '갑작스러웠나': 18,\n",
       " '박': 19,\n",
       " '돌아가서': 20,\n",
       " '선생님': 21,\n",
       " '물어': 22,\n",
       " '책임질': 23,\n",
       " '벗어나는': 24,\n",
       " 'PPL': 25,\n",
       " '죠': 26,\n",
       " '난다': 27,\n",
       " '제일': 28,\n",
       " '사랑': 29,\n",
       " '강원도': 30,\n",
       " '가까워질': 31,\n",
       " '다시': 32,\n",
       " '옷': 33,\n",
       " '보고': 34,\n",
       " '정': 35,\n",
       " '씨방': 36,\n",
       " '알': 37,\n",
       " '나': 38,\n",
       " '많이': 39,\n",
       " '맛있게': 40,\n",
       " '사세요': 41,\n",
       " '언제나': 42,\n",
       " '있는': 43,\n",
       " '어디': 44,\n",
       " '부모님': 45,\n",
       " '빼고': 46,\n",
       " '먹었는데': 47,\n",
       " '이야기': 48,\n",
       " '시간': 49,\n",
       " '으로': 50,\n",
       " '휴식': 51,\n",
       " '짧죠': 52,\n",
       " '될': 53,\n",
       " '알려': 54,\n",
       " '있을': 55,\n",
       " '학교': 56,\n",
       " '무시': 57,\n",
       " '도': 58,\n",
       " '보내고': 59,\n",
       " '먹을까': 60,\n",
       " '믿어': 61,\n",
       " '개시': 62,\n",
       " '켜고': 63,\n",
       " '거': 64,\n",
       " '이랑': 65,\n",
       " '득템': 66,\n",
       " '바라요': 67,\n",
       " '했길': 68,\n",
       " '그': 69,\n",
       " '습관': 70,\n",
       " '싶다': 71,\n",
       " '시켜': 72,\n",
       " '기회': 73,\n",
       " '준': 74,\n",
       " '돼겠지': 75,\n",
       " '붙잡고': 76,\n",
       " '개인': 77,\n",
       " '의': 78,\n",
       " '좋아요': 79,\n",
       " '설움': 80,\n",
       " '카드': 81,\n",
       " '못': 82,\n",
       " '입어볼까': 83,\n",
       " '개강': 84,\n",
       " '해보여': 85,\n",
       " '막': 86,\n",
       " '간접흡연': 87,\n",
       " '해볼까': 88,\n",
       " '이나': 89,\n",
       " 'ㅠㅠ': 90,\n",
       " '망가졌어': 91,\n",
       " '와': 92,\n",
       " '좋겠네요': 93,\n",
       " '3': 94,\n",
       " '있을까': 95,\n",
       " '살찐': 96,\n",
       " '쇼핑': 97,\n",
       " '쫄딱': 98,\n",
       " '떨어졌어': 99,\n",
       " '가야': 100,\n",
       " '없죠': 101,\n",
       " '간다': 102,\n",
       " '개념': 103,\n",
       " '가보세요': 104,\n",
       " '좋아해주세요': 105,\n",
       " '어서': 106,\n",
       " '것': 107,\n",
       " '켜놓고': 108,\n",
       " '데': 109,\n",
       " '새': 110,\n",
       " '서먹해졌어': 111,\n",
       " '간장': 112,\n",
       " '때': 113,\n",
       " '먹고': 114,\n",
       " '여행': 115,\n",
       " '했잖아': 116,\n",
       " '지망': 117,\n",
       " '있어요': 118,\n",
       " '있으면': 119,\n",
       " '하고': 120,\n",
       " '생활': 121,\n",
       " '하자고': 122,\n",
       " '사는': 123,\n",
       " '가서': 124,\n",
       " '수도': 125,\n",
       " '드는': 126,\n",
       " '키워': 127,\n",
       " '끼리': 128,\n",
       " '비싼데': 129,\n",
       " '걸린': 130,\n",
       " '땀': 131,\n",
       " '좋겠다': 132,\n",
       " '버렸어': 133,\n",
       " '자꾸': 134,\n",
       " '싫다': 135,\n",
       " '가출': 136,\n",
       " '나왔다': 137,\n",
       " '같이': 138,\n",
       " '땡': 139,\n",
       " '힘든데': 140,\n",
       " '집': 141,\n",
       " '감정': 142,\n",
       " '더': 143,\n",
       " '어제': 144,\n",
       " '중': 145,\n",
       " '오늘이': 146,\n",
       " '단': 147,\n",
       " '같아': 148,\n",
       " '병원': 149,\n",
       " '좋아': 150,\n",
       " '진창': 151,\n",
       " '있어도': 152,\n",
       " '이라니': 153,\n",
       " '수': 154,\n",
       " '하는지': 155,\n",
       " '반': 156,\n",
       " '저': 157,\n",
       " '같': 158,\n",
       " '않을': 159,\n",
       " '비': 160,\n",
       " '볼까': 161,\n",
       " '꼈어': 162,\n",
       " '에요': 163,\n",
       " '해보세요': 164,\n",
       " '눈물': 165,\n",
       " '졸려': 166,\n",
       " '닮아서': 167,\n",
       " '까': 168,\n",
       " '갈까': 169,\n",
       " '보고싶었나': 170,\n",
       " '고고': 171,\n",
       " '간식': 172,\n",
       " '감': 173,\n",
       " '싫어': 174,\n",
       " '피': 175,\n",
       " '업무': 176,\n",
       " '걔': 177,\n",
       " '가지': 178,\n",
       " '부족했나': 179,\n",
       " '알아차리지': 180,\n",
       " '떨리니까': 181,\n",
       " '생각': 182,\n",
       " '즐기세요': 183,\n",
       " '알아차려도': 184,\n",
       " '심하네': 185,\n",
       " '가고': 186,\n",
       " '지': 187,\n",
       " '모르고': 188,\n",
       " '주는': 189,\n",
       " '됨': 190,\n",
       " '매일': 191,\n",
       " '걸리겠어': 192,\n",
       " '들어올': 193,\n",
       " '정도': 194,\n",
       " '있어': 195,\n",
       " '정말': 196,\n",
       " '싶어': 197,\n",
       " '인거': 198,\n",
       " '쓰레기통': 199,\n",
       " '됐으면': 200,\n",
       " '감미로운': 201,\n",
       " '나온거': 202,\n",
       " '편해요': 203,\n",
       " '감히': 204,\n",
       " '진리': 205,\n",
       " '은': 206,\n",
       " '부터는': 207,\n",
       " '돈': 208,\n",
       " '취미': 209,\n",
       " '싫어하지': 210,\n",
       " '에는': 211,\n",
       " '없어': 212,\n",
       " '풀었어': 213,\n",
       " '말까': 214,\n",
       " '이에요': 215,\n",
       " '온': 216,\n",
       " '가려고': 217,\n",
       " '자도': 218,\n",
       " '애': 219,\n",
       " '해봐요': 220,\n",
       " '확실한': 221,\n",
       " '건데': 222,\n",
       " '적': 223,\n",
       " '봐서': 224,\n",
       " '절약': 225,\n",
       " '감기': 226,\n",
       " '자신': 227,\n",
       " '즐거운': 228,\n",
       " '가장': 229,\n",
       " '게임': 230,\n",
       " '수영장': 231,\n",
       " '하루': 232,\n",
       " '보면': 233,\n",
       " '나를': 234,\n",
       " '싫어요': 235,\n",
       " '나갔어': 236,\n",
       " '다음': 237,\n",
       " '애가': 238,\n",
       " '갈거야': 239,\n",
       " '가스': 240,\n",
       " '를': 241,\n",
       " '어떤것': 242,\n",
       " '가기': 243,\n",
       " '좋다': 244,\n",
       " '해도': 245,\n",
       " '기름': 246,\n",
       " '내일': 247,\n",
       " '낭비하지': 248,\n",
       " '결정': 249,\n",
       " '중요해요': 250,\n",
       " '상황': 251,\n",
       " '해주세요': 252,\n",
       " '가족': 253,\n",
       " '왜': 254,\n",
       " '하는데': 255,\n",
       " '위로': 256,\n",
       " '같은': 257,\n",
       " '집어서': 258,\n",
       " '무모한': 259,\n",
       " '하': 260,\n",
       " '할': 261,\n",
       " '4일': 262,\n",
       " '요': 263,\n",
       " '인게': 264,\n",
       " '친구': 265,\n",
       " '떨리는': 266,\n",
       " '빨리': 267,\n",
       " '망함': 268,\n",
       " '게': 269,\n",
       " '만들어': 270,\n",
       " '누구': 271,\n",
       " '눈살': 272,\n",
       " '방학': 273,\n",
       " '식혀주세요': 274,\n",
       " '기관': 275,\n",
       " '처음': 276,\n",
       " '함께': 277,\n",
       " '좋은': 278,\n",
       " '먼저': 279,\n",
       " '만나지': 280,\n",
       " '먹어야지': 281,\n",
       " '참': 282,\n",
       " '아는데': 283,\n",
       " '가세': 284,\n",
       " '이다': 285,\n",
       " '관리': 286,\n",
       " '두': 287,\n",
       " '자의': 288,\n",
       " '기운': 289,\n",
       " '놀러': 290,\n",
       " '서먹해': 291,\n",
       " '12시': 292,\n",
       " '자리': 293,\n",
       " '불편한': 294,\n",
       " '말랭이': 295,\n",
       " '가난한': 296,\n",
       " '이': 297,\n",
       " '야': 298,\n",
       " '해': 299,\n",
       " '사람': 300,\n",
       " '간만': 301,\n",
       " '데이터': 302,\n",
       " '안': 303,\n",
       " '잊고': 304,\n",
       " '중요한': 305,\n",
       " '물어보세요': 306,\n",
       " '달': 307,\n",
       " '너무': 308,\n",
       " '아세요': 309,\n",
       " '인데': 310,\n",
       " '자체': 311,\n",
       " '드립니다': 312,\n",
       " '건': 313,\n",
       " '3초': 314,\n",
       " '가자고': 315,\n",
       " '최고': 316,\n",
       " '공적': 317,\n",
       " '쉬는': 318,\n",
       " '갑자기': 319,\n",
       " '패턴': 320,\n",
       " '가네요': 321,\n",
       " '드세요': 322,\n",
       " '아름다운': 323,\n",
       " '끄고': 324,\n",
       " '입어': 325,\n",
       " '놓고': 326,\n",
       " '로': 327,\n",
       " '그건': 328,\n",
       " '살까': 329,\n",
       " '개': 330,\n",
       " '곧': 331,\n",
       " '봅니다': 332,\n",
       " '세수': 333,\n",
       " '아픈가요': 334,\n",
       " '찌푸려지죠': 335,\n",
       " '가': 336,\n",
       " '랑': 337,\n",
       " '행복': 338,\n",
       " '만': 339,\n",
       " '당신': 340,\n",
       " '연락': 341,\n",
       " '들더라': 342,\n",
       " '서로': 343,\n",
       " '스트레스': 344,\n",
       " '줘': 345,\n",
       " '봐요': 346,\n",
       " '그게': 347,\n",
       " '엉망': 348,\n",
       " '되도록': 349,\n",
       " '오세요': 350,\n",
       " '까지': 351,\n",
       " '누굴': 352,\n",
       " '하면': 353,\n",
       " '강렬한': 354,\n",
       " '남겨야': 355,\n",
       " '같아요': 356,\n",
       " '부터': 357,\n",
       " '치킨': 358,\n",
       " '했어': 359,\n",
       " '그럴': 360,\n",
       " '역시': 361,\n",
       " '뭘': 362,\n",
       " '리지': 363,\n",
       " '컨트롤': 364,\n",
       " '하겠어': 365,\n",
       " '일도': 366,\n",
       " '아님': 367,\n",
       " '새로': 368,\n",
       " '궁금해': 369,\n",
       " '인': 370,\n",
       " '살펴': 371,\n",
       " '사이': 372,\n",
       " '불': 373,\n",
       " '괜찮아요': 374,\n",
       " '일': 375,\n",
       " '운': 376,\n",
       " '된': 377,\n",
       " '낮잠': 378,\n",
       " '할까': 379,\n",
       " '연인': 380,\n",
       " '룩': 381,\n",
       " '곳': 382,\n",
       " '끌': 383,\n",
       " '오려나': 384,\n",
       " '키울까': 385,\n",
       " '사는게': 386,\n",
       " '장난': 387,\n",
       " '갈': 388,\n",
       " '예쁘게': 389,\n",
       " '옴': 390,\n",
       " '낭비': 391,\n",
       " '돼': 392,\n",
       " '관계': 393,\n",
       " '콕': 394,\n",
       " '가끔': 395,\n",
       " '강아지': 396,\n",
       " '가상': 397,\n",
       " '바빠서': 398,\n",
       " '되겠네요': 399,\n",
       " '변화': 400,\n",
       " '출발': 401,\n",
       " '자랑': 402,\n",
       " '가만': 403,\n",
       " '추천': 404,\n",
       " '첫인상': 405,\n",
       " '하느라': 406,\n",
       " '이럴': 407,\n",
       " '짠으로': 408,\n",
       " '좋더라': 409,\n",
       " '되': 410,\n",
       " '나쁜': 411,\n",
       " '후회': 412,\n",
       " '하지': 413,\n",
       " '물어봐서': 414,\n",
       " '따뜻하게': 415,\n",
       " '어필': 416,\n",
       " '키우고': 417,\n",
       " '이야': 418,\n",
       " '목소리': 419,\n",
       " '싶네요': 420,\n",
       " '모두': 421,\n",
       " '듣고': 422,\n",
       " '강의': 423,\n",
       " '한테': 424,\n",
       " '좋죠': 425,\n",
       " '하는': 426,\n",
       " '말': 427,\n",
       " '마음': 428,\n",
       " '뭐': 429,\n",
       " '당황': 430,\n",
       " '개학': 431,\n",
       " '예요': 432,\n",
       " '잠깐': 433,\n",
       " 'SNS': 434,\n",
       " '잘': 435,\n",
       " '시켜야지': 436,\n",
       " '또': 437,\n",
       " '고민': 438,\n",
       " '약': 439,\n",
       " 'SD': 440,\n",
       " '내': 441,\n",
       " '화폐': 442,\n",
       " '매력': 443,\n",
       " '1': 444,\n",
       " '다': 445,\n",
       " '혼자': 446,\n",
       " '니까': 447,\n",
       " '키울': 448,\n",
       " '질질': 449,\n",
       " '보세요': 450,\n",
       " '소중해요': 451,\n",
       " '마세요': 452,\n",
       " '살쪄도': 453}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 -> 인덱스\n",
    "# 문장을 인덱스로 변환하여 모델 입력으로 사용\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PADDING>',\n",
       " 1: '<START>',\n",
       " 2: '<END>',\n",
       " 3: '<OOV>',\n",
       " 4: '맞팔',\n",
       " 5: '을',\n",
       " 6: '는',\n",
       " 7: '보게',\n",
       " 8: '되나',\n",
       " 9: '싶은데',\n",
       " 10: '하세요',\n",
       " 11: '에',\n",
       " 12: '나오세요',\n",
       " 13: '왔나',\n",
       " 14: '그런거니',\n",
       " 15: '처럼',\n",
       " 16: '들',\n",
       " 17: '필요하죠',\n",
       " 18: '갑작스러웠나',\n",
       " 19: '박',\n",
       " 20: '돌아가서',\n",
       " 21: '선생님',\n",
       " 22: '물어',\n",
       " 23: '책임질',\n",
       " 24: '벗어나는',\n",
       " 25: 'PPL',\n",
       " 26: '죠',\n",
       " 27: '난다',\n",
       " 28: '제일',\n",
       " 29: '사랑',\n",
       " 30: '강원도',\n",
       " 31: '가까워질',\n",
       " 32: '다시',\n",
       " 33: '옷',\n",
       " 34: '보고',\n",
       " 35: '정',\n",
       " 36: '씨방',\n",
       " 37: '알',\n",
       " 38: '나',\n",
       " 39: '많이',\n",
       " 40: '맛있게',\n",
       " 41: '사세요',\n",
       " 42: '언제나',\n",
       " 43: '있는',\n",
       " 44: '어디',\n",
       " 45: '부모님',\n",
       " 46: '빼고',\n",
       " 47: '먹었는데',\n",
       " 48: '이야기',\n",
       " 49: '시간',\n",
       " 50: '으로',\n",
       " 51: '휴식',\n",
       " 52: '짧죠',\n",
       " 53: '될',\n",
       " 54: '알려',\n",
       " 55: '있을',\n",
       " 56: '학교',\n",
       " 57: '무시',\n",
       " 58: '도',\n",
       " 59: '보내고',\n",
       " 60: '먹을까',\n",
       " 61: '믿어',\n",
       " 62: '개시',\n",
       " 63: '켜고',\n",
       " 64: '거',\n",
       " 65: '이랑',\n",
       " 66: '득템',\n",
       " 67: '바라요',\n",
       " 68: '했길',\n",
       " 69: '그',\n",
       " 70: '습관',\n",
       " 71: '싶다',\n",
       " 72: '시켜',\n",
       " 73: '기회',\n",
       " 74: '준',\n",
       " 75: '돼겠지',\n",
       " 76: '붙잡고',\n",
       " 77: '개인',\n",
       " 78: '의',\n",
       " 79: '좋아요',\n",
       " 80: '설움',\n",
       " 81: '카드',\n",
       " 82: '못',\n",
       " 83: '입어볼까',\n",
       " 84: '개강',\n",
       " 85: '해보여',\n",
       " 86: '막',\n",
       " 87: '간접흡연',\n",
       " 88: '해볼까',\n",
       " 89: '이나',\n",
       " 90: 'ㅠㅠ',\n",
       " 91: '망가졌어',\n",
       " 92: '와',\n",
       " 93: '좋겠네요',\n",
       " 94: '3',\n",
       " 95: '있을까',\n",
       " 96: '살찐',\n",
       " 97: '쇼핑',\n",
       " 98: '쫄딱',\n",
       " 99: '떨어졌어',\n",
       " 100: '가야',\n",
       " 101: '없죠',\n",
       " 102: '간다',\n",
       " 103: '개념',\n",
       " 104: '가보세요',\n",
       " 105: '좋아해주세요',\n",
       " 106: '어서',\n",
       " 107: '것',\n",
       " 108: '켜놓고',\n",
       " 109: '데',\n",
       " 110: '새',\n",
       " 111: '서먹해졌어',\n",
       " 112: '간장',\n",
       " 113: '때',\n",
       " 114: '먹고',\n",
       " 115: '여행',\n",
       " 116: '했잖아',\n",
       " 117: '지망',\n",
       " 118: '있어요',\n",
       " 119: '있으면',\n",
       " 120: '하고',\n",
       " 121: '생활',\n",
       " 122: '하자고',\n",
       " 123: '사는',\n",
       " 124: '가서',\n",
       " 125: '수도',\n",
       " 126: '드는',\n",
       " 127: '키워',\n",
       " 128: '끼리',\n",
       " 129: '비싼데',\n",
       " 130: '걸린',\n",
       " 131: '땀',\n",
       " 132: '좋겠다',\n",
       " 133: '버렸어',\n",
       " 134: '자꾸',\n",
       " 135: '싫다',\n",
       " 136: '가출',\n",
       " 137: '나왔다',\n",
       " 138: '같이',\n",
       " 139: '땡',\n",
       " 140: '힘든데',\n",
       " 141: '집',\n",
       " 142: '감정',\n",
       " 143: '더',\n",
       " 144: '어제',\n",
       " 145: '중',\n",
       " 146: '오늘이',\n",
       " 147: '단',\n",
       " 148: '같아',\n",
       " 149: '병원',\n",
       " 150: '좋아',\n",
       " 151: '진창',\n",
       " 152: '있어도',\n",
       " 153: '이라니',\n",
       " 154: '수',\n",
       " 155: '하는지',\n",
       " 156: '반',\n",
       " 157: '저',\n",
       " 158: '같',\n",
       " 159: '않을',\n",
       " 160: '비',\n",
       " 161: '볼까',\n",
       " 162: '꼈어',\n",
       " 163: '에요',\n",
       " 164: '해보세요',\n",
       " 165: '눈물',\n",
       " 166: '졸려',\n",
       " 167: '닮아서',\n",
       " 168: '까',\n",
       " 169: '갈까',\n",
       " 170: '보고싶었나',\n",
       " 171: '고고',\n",
       " 172: '간식',\n",
       " 173: '감',\n",
       " 174: '싫어',\n",
       " 175: '피',\n",
       " 176: '업무',\n",
       " 177: '걔',\n",
       " 178: '가지',\n",
       " 179: '부족했나',\n",
       " 180: '알아차리지',\n",
       " 181: '떨리니까',\n",
       " 182: '생각',\n",
       " 183: '즐기세요',\n",
       " 184: '알아차려도',\n",
       " 185: '심하네',\n",
       " 186: '가고',\n",
       " 187: '지',\n",
       " 188: '모르고',\n",
       " 189: '주는',\n",
       " 190: '됨',\n",
       " 191: '매일',\n",
       " 192: '걸리겠어',\n",
       " 193: '들어올',\n",
       " 194: '정도',\n",
       " 195: '있어',\n",
       " 196: '정말',\n",
       " 197: '싶어',\n",
       " 198: '인거',\n",
       " 199: '쓰레기통',\n",
       " 200: '됐으면',\n",
       " 201: '감미로운',\n",
       " 202: '나온거',\n",
       " 203: '편해요',\n",
       " 204: '감히',\n",
       " 205: '진리',\n",
       " 206: '은',\n",
       " 207: '부터는',\n",
       " 208: '돈',\n",
       " 209: '취미',\n",
       " 210: '싫어하지',\n",
       " 211: '에는',\n",
       " 212: '없어',\n",
       " 213: '풀었어',\n",
       " 214: '말까',\n",
       " 215: '이에요',\n",
       " 216: '온',\n",
       " 217: '가려고',\n",
       " 218: '자도',\n",
       " 219: '애',\n",
       " 220: '해봐요',\n",
       " 221: '확실한',\n",
       " 222: '건데',\n",
       " 223: '적',\n",
       " 224: '봐서',\n",
       " 225: '절약',\n",
       " 226: '감기',\n",
       " 227: '자신',\n",
       " 228: '즐거운',\n",
       " 229: '가장',\n",
       " 230: '게임',\n",
       " 231: '수영장',\n",
       " 232: '하루',\n",
       " 233: '보면',\n",
       " 234: '나를',\n",
       " 235: '싫어요',\n",
       " 236: '나갔어',\n",
       " 237: '다음',\n",
       " 238: '애가',\n",
       " 239: '갈거야',\n",
       " 240: '가스',\n",
       " 241: '를',\n",
       " 242: '어떤것',\n",
       " 243: '가기',\n",
       " 244: '좋다',\n",
       " 245: '해도',\n",
       " 246: '기름',\n",
       " 247: '내일',\n",
       " 248: '낭비하지',\n",
       " 249: '결정',\n",
       " 250: '중요해요',\n",
       " 251: '상황',\n",
       " 252: '해주세요',\n",
       " 253: '가족',\n",
       " 254: '왜',\n",
       " 255: '하는데',\n",
       " 256: '위로',\n",
       " 257: '같은',\n",
       " 258: '집어서',\n",
       " 259: '무모한',\n",
       " 260: '하',\n",
       " 261: '할',\n",
       " 262: '4일',\n",
       " 263: '요',\n",
       " 264: '인게',\n",
       " 265: '친구',\n",
       " 266: '떨리는',\n",
       " 267: '빨리',\n",
       " 268: '망함',\n",
       " 269: '게',\n",
       " 270: '만들어',\n",
       " 271: '누구',\n",
       " 272: '눈살',\n",
       " 273: '방학',\n",
       " 274: '식혀주세요',\n",
       " 275: '기관',\n",
       " 276: '처음',\n",
       " 277: '함께',\n",
       " 278: '좋은',\n",
       " 279: '먼저',\n",
       " 280: '만나지',\n",
       " 281: '먹어야지',\n",
       " 282: '참',\n",
       " 283: '아는데',\n",
       " 284: '가세',\n",
       " 285: '이다',\n",
       " 286: '관리',\n",
       " 287: '두',\n",
       " 288: '자의',\n",
       " 289: '기운',\n",
       " 290: '놀러',\n",
       " 291: '서먹해',\n",
       " 292: '12시',\n",
       " 293: '자리',\n",
       " 294: '불편한',\n",
       " 295: '말랭이',\n",
       " 296: '가난한',\n",
       " 297: '이',\n",
       " 298: '야',\n",
       " 299: '해',\n",
       " 300: '사람',\n",
       " 301: '간만',\n",
       " 302: '데이터',\n",
       " 303: '안',\n",
       " 304: '잊고',\n",
       " 305: '중요한',\n",
       " 306: '물어보세요',\n",
       " 307: '달',\n",
       " 308: '너무',\n",
       " 309: '아세요',\n",
       " 310: '인데',\n",
       " 311: '자체',\n",
       " 312: '드립니다',\n",
       " 313: '건',\n",
       " 314: '3초',\n",
       " 315: '가자고',\n",
       " 316: '최고',\n",
       " 317: '공적',\n",
       " 318: '쉬는',\n",
       " 319: '갑자기',\n",
       " 320: '패턴',\n",
       " 321: '가네요',\n",
       " 322: '드세요',\n",
       " 323: '아름다운',\n",
       " 324: '끄고',\n",
       " 325: '입어',\n",
       " 326: '놓고',\n",
       " 327: '로',\n",
       " 328: '그건',\n",
       " 329: '살까',\n",
       " 330: '개',\n",
       " 331: '곧',\n",
       " 332: '봅니다',\n",
       " 333: '세수',\n",
       " 334: '아픈가요',\n",
       " 335: '찌푸려지죠',\n",
       " 336: '가',\n",
       " 337: '랑',\n",
       " 338: '행복',\n",
       " 339: '만',\n",
       " 340: '당신',\n",
       " 341: '연락',\n",
       " 342: '들더라',\n",
       " 343: '서로',\n",
       " 344: '스트레스',\n",
       " 345: '줘',\n",
       " 346: '봐요',\n",
       " 347: '그게',\n",
       " 348: '엉망',\n",
       " 349: '되도록',\n",
       " 350: '오세요',\n",
       " 351: '까지',\n",
       " 352: '누굴',\n",
       " 353: '하면',\n",
       " 354: '강렬한',\n",
       " 355: '남겨야',\n",
       " 356: '같아요',\n",
       " 357: '부터',\n",
       " 358: '치킨',\n",
       " 359: '했어',\n",
       " 360: '그럴',\n",
       " 361: '역시',\n",
       " 362: '뭘',\n",
       " 363: '리지',\n",
       " 364: '컨트롤',\n",
       " 365: '하겠어',\n",
       " 366: '일도',\n",
       " 367: '아님',\n",
       " 368: '새로',\n",
       " 369: '궁금해',\n",
       " 370: '인',\n",
       " 371: '살펴',\n",
       " 372: '사이',\n",
       " 373: '불',\n",
       " 374: '괜찮아요',\n",
       " 375: '일',\n",
       " 376: '운',\n",
       " 377: '된',\n",
       " 378: '낮잠',\n",
       " 379: '할까',\n",
       " 380: '연인',\n",
       " 381: '룩',\n",
       " 382: '곳',\n",
       " 383: '끌',\n",
       " 384: '오려나',\n",
       " 385: '키울까',\n",
       " 386: '사는게',\n",
       " 387: '장난',\n",
       " 388: '갈',\n",
       " 389: '예쁘게',\n",
       " 390: '옴',\n",
       " 391: '낭비',\n",
       " 392: '돼',\n",
       " 393: '관계',\n",
       " 394: '콕',\n",
       " 395: '가끔',\n",
       " 396: '강아지',\n",
       " 397: '가상',\n",
       " 398: '바빠서',\n",
       " 399: '되겠네요',\n",
       " 400: '변화',\n",
       " 401: '출발',\n",
       " 402: '자랑',\n",
       " 403: '가만',\n",
       " 404: '추천',\n",
       " 405: '첫인상',\n",
       " 406: '하느라',\n",
       " 407: '이럴',\n",
       " 408: '짠으로',\n",
       " 409: '좋더라',\n",
       " 410: '되',\n",
       " 411: '나쁜',\n",
       " 412: '후회',\n",
       " 413: '하지',\n",
       " 414: '물어봐서',\n",
       " 415: '따뜻하게',\n",
       " 416: '어필',\n",
       " 417: '키우고',\n",
       " 418: '이야',\n",
       " 419: '목소리',\n",
       " 420: '싶네요',\n",
       " 421: '모두',\n",
       " 422: '듣고',\n",
       " 423: '강의',\n",
       " 424: '한테',\n",
       " 425: '좋죠',\n",
       " 426: '하는',\n",
       " 427: '말',\n",
       " 428: '마음',\n",
       " 429: '뭐',\n",
       " 430: '당황',\n",
       " 431: '개학',\n",
       " 432: '예요',\n",
       " 433: '잠깐',\n",
       " 434: 'SNS',\n",
       " 435: '잘',\n",
       " 436: '시켜야지',\n",
       " 437: '또',\n",
       " 438: '고민',\n",
       " 439: '약',\n",
       " 440: 'SD',\n",
       " 441: '내',\n",
       " 442: '화폐',\n",
       " 443: '매력',\n",
       " 444: '1',\n",
       " 445: '다',\n",
       " 446: '혼자',\n",
       " 447: '니까',\n",
       " 448: '키울',\n",
       " 449: '질질',\n",
       " 450: '보세요',\n",
       " 451: '소중해요',\n",
       " 452: '마세요',\n",
       " 453: '살쪄도'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 -> 단어\n",
    "# 모델의 예측 결과인 인덱스를 문장으로 변환시 사용\n",
    "index_to_word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "def convert_text_to_index(sentences, vocabulary, type): \n",
    "    \n",
    "    sentences_index = []\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for sentence in sentences:\n",
    "        sentence_index = []\n",
    "        \n",
    "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
    "        if type == DECODER_INPUT:\n",
    "            sentence_index.extend([vocabulary[STA]])\n",
    "        \n",
    "        # 문장의 단어들을 띄어쓰기로 분리\n",
    "        for word in sentence.split():\n",
    "            if vocabulary.get(word) is not None:\n",
    "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[word]])\n",
    "            else:\n",
    "                # 사전에 없는 단어면 OOV 인덱스를 추가\n",
    "                sentence_index.extend([vocabulary[OOV]])\n",
    "\n",
    "        # 최대 길이 검사\n",
    "        if type == DECODER_TARGET:\n",
    "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
    "            if len(sentence_index) >= max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
    "            else:\n",
    "                sentence_index += [vocabulary[END]]\n",
    "        else:\n",
    "            if len(sentence_index) > max_sequences:\n",
    "                sentence_index = sentence_index[:max_sequences]\n",
    "            \n",
    "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
    "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
    "        \n",
    "        # 문장의 인덱스 배열을 추가\n",
    "        sentences_index.append(sentence_index)\n",
    "\n",
    "    return np.asarray(sentences_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq에서는 학습시 다음과 같이 총 3개의 데이터가 필요합니다.\n",
    "\n",
    "인코더 입력 : 12시 땡<br>\n",
    "디코더 입력 : START 하루 가 또 가네요<br>\n",
    "디코더 출력 : 하루 가 또 가네요 END\n",
    "<br>\n",
    "원래 Seq2Seq는 디코더의 현재 출력이 디코더의 다음 입력으로 들어갑니다.<br>\n",
    "다만 학습에서는 굳이 이렇게 하지 않고 디코더 입력과 디코더 출력의 데이터를 각각 만듭니다. <br>\n",
    "<br>\n",
    "그러나 예측시에는 이런 방식이 불가능합니다.<br>\n",
    "출력값을 미리 알지 못하기 때문에, 디코더 입력을 사전에 생성할 수가 없습니다.<br>\n",
    "이런 문제를 해결하기 위해 훈련 모델과 예측 모델을 따로 구성해야 합니다.<br>\n",
    "모델 생성 부분에서 다시 자세히 설명을 드리겠습니다.<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 question: 12시 땡\n",
      "첫번째 Encoder 입력: [292 139   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "index_to_word[ 125 ]: 수도\n",
      "index_to_word[ 308 ]: 너무\n"
     ]
    }
   ],
   "source": [
    "# 인코더 입력 인덱스 변환\n",
    "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
    "\n",
    "print('첫번째 question:', question[0])\n",
    "# 첫 번째 인코더 입력 출력 (12시 땡)\n",
    "print('첫번째 Encoder 입력:',x_encoder[0])\n",
    "print()\n",
    "\n",
    "# 출력된 125, 308은 word의 index\n",
    "print('index_to_word[ 125 ]:', index_to_word[ 125 ])\n",
    "print('index_to_word[ 308 ]:', index_to_word[ 308 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 answer: 하루 가 또 가네요\n",
      "첫번째 Decoder input: [  1 232 336 437 321   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "index_to_word[   1 ]: <START>\n",
      "index_to_word[ 259 ]: 무모한\n",
      "index_to_word[ 223 ]: 적\n",
      "index_to_word[ 114 ]: 먹고\n",
      "index_to_word[  74 ]: 준\n"
     ]
    }
   ],
   "source": [
    "# 디코더 입력 인덱스 변환\n",
    "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
    "\n",
    "print('첫번째 answer:', answer[0])\n",
    "print('첫번째 Decoder input:', x_decoder[0])\n",
    "print()\n",
    "\n",
    "# 출력된 1, 259, 223, 114, 74는 word의 index\n",
    "print('index_to_word[   1 ]:', index_to_word[   1 ])\n",
    "print('index_to_word[ 259 ]:', index_to_word[ 259 ])\n",
    "print('index_to_word[ 223 ]:', index_to_word[ 223 ])\n",
    "print('index_to_word[ 114 ]:', index_to_word[ 114 ])\n",
    "print('index_to_word[  74 ]:', index_to_word[  74 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 answer: 하루 가 또 가네요\n",
      "첫번쨰 Decoder onput: [232 336 437 321   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "\n",
      "index_to_word[ 259 ]: 무모한\n",
      "index_to_word[ 223 ]: 적\n",
      "index_to_word[ 114 ]: 먹고\n",
      "index_to_word[  74 ]: 준\n",
      "index_to_word[   2 ]: <END>\n"
     ]
    }
   ],
   "source": [
    "# 디코더 목표 인덱스 변환\n",
    "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
    "\n",
    "# 첫 번째 디코더 목표 출력 (하루 가 또 가네요 END)\n",
    "y_decoder[0]\n",
    "\n",
    "print('첫번째 answer:', answer[0])\n",
    "print('첫번쨰 Decoder onput:', y_decoder[0])\n",
    "print()\n",
    "\n",
    "# 출력된 1, 259, 223, 114, 74는 word의 index\n",
    "print('index_to_word[ 259 ]:', index_to_word[ 259 ])\n",
    "print('index_to_word[ 223 ]:', index_to_word[ 223 ])\n",
    "print('index_to_word[ 114 ]:', index_to_word[ 114 ])\n",
    "print('index_to_word[  74 ]:', index_to_word[  74 ])\n",
    "print('index_to_word[   2 ]:', index_to_word[   2 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫인코딩 초기화\n",
    "one_hot_data = np.zeros((len(y_decoder), max_sequences, len(words)))\n",
    "one_hot_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([232, 336, 437, 321,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one_hot_data의 첫 row에 259번째 column에 '하루'\n",
    "#one_hot_data의 첫 row에 223번째 column에 '가'\n",
    "#one_hot_data의 첫 row에 114번째 column에 '또'.... 를 1로 변경\n",
    "y_decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디코더 목표를 원핫인코딩으로 변환\n",
    "# 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
    "for i, sequence in enumerate(y_decoder):\n",
    "    for j, index in enumerate(sequence):\n",
    "        one_hot_data[i, j, index] = 1\n",
    "\n",
    "# 디코더 목표 설정\n",
    "y_decoder = one_hot_data\n",
    "\n",
    "# 첫 번째 디코더 목표 출력\n",
    "y_decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 259번째 index (하루) 가 1임\n",
    "y_decoder[0][0][112]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더 입력과 디코더 입력은 임베딩 레이어에 들어가는 인덱스 배열입니다.<br>\n",
    "반면에 디코더 출력은 원핫인코딩 형식이 되어야 합니다.<br>\n",
    "디코더의 마지막 Dense 레이어에서 softmax로 나오기 때문입니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "encoder_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "encoder_outputs = layers.Embedding(len(words), embedding_dim)(encoder_inputs)\n",
    "\n",
    "# return_state가 True면 상태값 리턴\n",
    "# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n",
    "encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_dim,\n",
    "                                                dropout=0.1,\n",
    "                                                recurrent_dropout=0.5,\n",
    "                                                return_state=True)(encoder_outputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "# Decoder의 initial state에 넣어주기 위함\n",
    "# 즉, input sentence의 모든 정보를 통해 Decoding 하기 위함\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm')>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm')>,\n",
       " <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm')>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "decoder_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_embedding = layers.Embedding(len(words), embedding_dim)\n",
    "decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n",
    "# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n",
    "decoder_lstm = layers.LSTM(lstm_hidden_dim,\n",
    "                           dropout=0.1,\n",
    "                           recurrent_dropout=0.5,\n",
    "                           return_state=True,\n",
    "                           return_sequences=True)\n",
    "\n",
    "# initial_state를 인코더의 상태로 초기화\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_dense = layers.Dense(len(words), activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지의 예제는 Sequential 방식의 모델이었습니다.<br>\n",
    "하지만 이번에는 함수형 API 모델을 사용했습니다.<br>\n",
    "인코더와 디코더가 따로 분리되어야 하는데, 단순히 레이어를 추가하여 붙이는 순차형으로는 구현이 불가능하기 때문입니다. <br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 훈련 모델 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력과 출력으로 함수형 API 모델 생성\n",
    "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# 학습 방법 설정\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model() 함수로 입력과 출력을 따로 설정하여 모델을 만듭니다.<br>\n",
    "그다음 compile과 fit은 이전과 동일하게 적용하시면 됩니다.<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "#  예측 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
    "encoder_model = models.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "#--------------------------------------------\n",
    "# 예측 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n",
    "# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n",
    "decoder_state_input_h = layers.Input(shape=(lstm_hidden_dim,))\n",
    "decoder_state_input_c = layers.Input(shape=(lstm_hidden_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_outputs = decoder_embedding(decoder_inputs)\n",
    "\n",
    "# LSTM 레이어\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n",
    "                                                 initial_state=decoder_states_inputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 예측 모델 디코더 설정\n",
    "decoder_model = models.Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 모델은 이미 학습된 훈련 모델의 레이어들을 그대로 재사용합니다. 예측 모델 인코더는 훈련 모델 인코더과 동일합니다. 그러나 예측 모델 디코더는 매번 LSTM 상태값을 입력으로 받습니다. 또한 디코더의 LSTM 상태를 출력값과 같이 내보내서, 다음 번 입력에 넣습니다. \n",
    "\n",
    "이렇게 하는 이유는 LSTM을 딱 한번의 타임 스텝만 실행하기 때문입니다. 그래서 매번 상태값을 새로 초기화 해야 합니다. 이와 반대로 훈련할때는 문장 전체를 계속 LSTM으로 돌리기 때문에 자동으로 상태값이 전달됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 100)    45400       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    45400       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 128),        117248      ['embedding[0][0]']              \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 128),  117248      ['embedding_1[0][0]',            \n",
      "                                 (None, 128),                     'lstm[0][1]',                   \n",
      "                                 (None, 128)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 454)    58566       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 383,862\n",
      "Trainable params: 383,862\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         45400     \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 128),             117248    \n",
      "                              (None, 128),                       \n",
      "                              (None, 128)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 162,648\n",
      "Trainable params: 162,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    45400       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 128),  117248      ['embedding_1[1][0]',            \n",
      "                                 (None, 128),                     'input_3[0][0]',                \n",
      "                                 (None, 128)]                     'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 454)    58566       ['lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 221,214\n",
      "Trainable params: 221,214\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder_model에는 \n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 훈련 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 문장으로 변환\n",
    "def convert_index_to_text(indexs, vocabulary): \n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for index in indexs:\n",
    "        if index == END_INDEX:\n",
    "            # 종료 인덱스면 중지\n",
    "            break;\n",
    "        elif vocabulary.get(index) is not None:\n",
    "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
    "            sentence += vocabulary[index]\n",
    "        else:\n",
    "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
    "            sentence += vocabulary[OOV_INDEX]\n",
    "            \n",
    "        # 빈칸 추가\n",
    "        sentence += ' '\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Epoch : 1\n",
      "accuracy : 0.8416666388511658\n",
      "loss : 0.7041441202163696\n",
      "1/1 [==============================] - 1s 963ms/step\n",
      "저 도 이 \n",
      "\n",
      "Total Epoch : 2\n",
      "accuracy : 0.9253333210945129\n",
      "loss : 0.3601609468460083\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "맛있게 도 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 3\n",
      "accuracy : 0.9679999947547913\n",
      "loss : 0.1488395631313324\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "빨리 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 4\n",
      "accuracy : 0.9743333458900452\n",
      "loss : 0.08869320154190063\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 5\n",
      "accuracy : 0.9776666760444641\n",
      "loss : 0.06836984306573868\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 6\n",
      "accuracy : 0.9816666841506958\n",
      "loss : 0.05431702733039856\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 7\n",
      "accuracy : 0.9883333444595337\n",
      "loss : 0.04235469177365303\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 8\n",
      "accuracy : 0.9926666617393494\n",
      "loss : 0.026115138083696365\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 9\n",
      "accuracy : 0.9946666955947876\n",
      "loss : 0.016972223296761513\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 10\n",
      "accuracy : 0.996666669845581\n",
      "loss : 0.011107049882411957\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 11\n",
      "accuracy : 0.9976666569709778\n",
      "loss : 0.007442858070135117\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 12\n",
      "accuracy : 0.9980000257492065\n",
      "loss : 0.007182784844189882\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 13\n",
      "accuracy : 0.9986666440963745\n",
      "loss : 0.005231610964983702\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 14\n",
      "accuracy : 0.9986666440963745\n",
      "loss : 0.004294945392757654\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 15\n",
      "accuracy : 0.999666690826416\n",
      "loss : 0.0013761575100943446\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 16\n",
      "accuracy : 0.9983333349227905\n",
      "loss : 0.004293395671993494\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 17\n",
      "accuracy : 1.0\n",
      "loss : 0.0002500653499737382\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 18\n",
      "accuracy : 1.0\n",
      "loss : 0.00022982945665717125\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 19\n",
      "accuracy : 1.0\n",
      "loss : 5.56121849513147e-05\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 20\n",
      "accuracy : 1.0\n",
      "loss : 5.593769674305804e-05\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "여행 은 언제나 좋죠 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 에폭 반복\n",
    "for epoch in range(20):\n",
    "    print('Total Epoch :', epoch + 1)\n",
    "\n",
    "    # 훈련 시작\n",
    "    history = model.fit([x_encoder, x_decoder],\n",
    "                        y_decoder,\n",
    "                        epochs=100,\n",
    "                        batch_size=64,\n",
    "                        verbose=0)\n",
    "    \n",
    "    # 정확도와 손실 출력\n",
    "    print('accuracy :', history.history['acc'][-1])\n",
    "    print('loss :', history.history['loss'][-1])\n",
    "    \n",
    "    # 문장 예측 테스트\n",
    "    # (3 박 4일 놀러 가고 싶다) -> (여행 은 언제나 좋죠)\n",
    "    input_encoder = x_encoder[2].reshape(1, x_encoder[2].shape[0])\n",
    "    input_decoder = x_decoder[2].reshape(1, x_decoder[2].shape[0])\n",
    "    results = model.predict([input_encoder, input_decoder])\n",
    "    \n",
    "    # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "    # 1축을 기준으로 가장 높은 값의 위치를 구함\n",
    "    indexs = np.argmax(results[0], 1) \n",
    "    \n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "    print(sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 진행될수록 예측 문장이 제대로 생성되는 것을 볼 수 있습니다. 다만 여기서의 예측은 단순히 테스트를 위한 것이라, 인코더 입력과 디코더 입력 데이터가 동시에 사용됩니다. 아래 문장 생성에서는 예측 모델을 적용하기 때문에, 오직 인코더 입력 데이터만 집어 넣습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "encoder_model.save('./model/seq2seq_chatbot_encoder_model.h5')\n",
    "decoder_model.save('./model/seq2seq_chatbot_decoder_model.h5')\n",
    "\n",
    "# 인덱스 저장\n",
    "with open('./model/word_to_index.pkl', 'wb') as f:\n",
    "    pickle.dump(word_to_index, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('./model/index_to_word.pkl', 'wb') as f:\n",
    "    pickle.dump(index_to_word, f, pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 모델 파일 로드\n",
    "encoder_model = models.load_model('./model/seq2seq_chatbot_encoder_model.h5')\n",
    "decoder_model = models.load_model('./model/seq2seq_chatbot_decoder_model.h5')\n",
    "\n",
    "# 인덱스 파일 로드\n",
    "with open('./model/word_to_index.pkl', 'rb') as f:\n",
    "    word_to_index = pickle.load(f)\n",
    "with open('./model/index_to_word.pkl', 'rb') as f:\n",
    "    index_to_word = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측을 위한 입력 생성\n",
    "def make_predict_input(sentence):\n",
    "\n",
    "    sentences = []\n",
    "    sentences.append(sentence)\n",
    "    sentences = pos_tag(sentences)\n",
    "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
    "    \n",
    "    return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성\n",
    "def generate_text(input_seq):\n",
    "    \n",
    "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
    "    states = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 목표 시퀀스 초기화\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
    "    target_seq[0, 0] = STA_INDEX\n",
    "    \n",
    "    # 인덱스 초기화\n",
    "    indexs = []\n",
    "    \n",
    "    # 디코더 타임 스텝 반복\n",
    "    while 1:\n",
    "        # 디코더로 현재 타임 스텝 출력 구함\n",
    "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
    "        decoder_outputs, state_h, state_c = decoder_model.predict(\n",
    "                                                [target_seq] + states)\n",
    "\n",
    "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "        index = np.argmax(decoder_outputs[0, 0, :])\n",
    "        indexs.append(index)\n",
    "        \n",
    "        # 종료 검사\n",
    "        if index == END_INDEX or len(indexs) >= max_sequences:\n",
    "            break\n",
    "\n",
    "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = index\n",
    "        \n",
    "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "제일 첫 단어는 START로 시작합니다. 그리고 출력으로 나온 인덱스를 디코더 입력으로 넣고 다시 예측을 반복합니다. 상태값을 받아 다시 입력으로 같이 넣는 것에 주의하시기 바랍니다. END 태그가 나오면 문장 생성을 종료합니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3, 297,  79,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('휴강이 좋아요')\n",
    "input_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 458ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그 사람 도 그럴 거 예요 '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋에 있는 문장과 똑같은 입력을 넣으니, 역시 정확히 일치하는 답변이 출력되었습니다.\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[302, 423, 308,  79,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('데이터 강의 너무 좋아요')\n",
    "input_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마음 이 아픈가요 '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최고의 강의입니다\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,  19,   3,   3, 327,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('4박5일 욜로가려고요')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'혼자 도 좋아요 '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 데이터셋에 없던 '4박5일, 욜로'로 입력을 수정하니, 전혀 다른 문장이 출력되었습니다.<br>\n",
    "이는 우리가 데이터의 일부인 100개 문장만 학습했기 때문입니다.<br>\n",
    "데이터의 개수를 늘려서 훈련할수록 일반화 능력이 더욱 높아집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
